---
title: "Quiz 1"
author: "Modern Data Mining"
date: "January 31, 2017"
documentclass: exam-mod
output:
  pdf_document: 
     keep_tex: false
fontfamily: mathpazo
fontsize: 11pt
geometry: margin=1in
header-includes:
   - \linespread{1.05}
   - \usepackage{framed}
   - \usepackage{fancyvrb}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height=4, fig.width=7, warning = T)
options(scipen = 1, digits = 3)
# install.packages("pacman")
library("pacman")
pacman::p_load(dplyr, ggplot2, magrittr, gridExtra, reshape, rmarkdown)
```

<!-- \makebox[\textwidth]{\textbf{Name}:\enspace\hrulefill} -->
<!-- \vspace{0.4in} -->
<!-- \makebox[\textwidth]{\textbf{Section (471, 571, 701)}:\enspace\hrulefill} -->

Instruction: This is an open book, 10-minute quiz. Check the correction answer from the bubble sheet and turn in the answer sheet only.

\vspace{.1in}
Predicting Price of the wine based on weather. In the early 1990s, Orley Ashenfelter, an Economics Professor at Princeton University claimed to have found a method to predict the quality of Bordeaux wine, and hence its price, without tasting a single drop\footnote{This data is used in the paper http://www.liquidasset.com/orley.htm and chapter 1 of the book "Super Crunchers: Why Thinking-by-Numbers is the new to be smart".}.


There are six variables in the data:

`Year:` Year in which the wine was produced. This is a unique identifier for each observation.

`LogPrice:` Logarithm of the price of the wine (indicative of quality). This is what we try to predict.

`WinterRain:` Winter rain in the Bordeaux region in ml, rain during the months October to March.

`Temperature:` Average temperature in the region, during the months April to September, in degrees Celsius.

`HarvestRain:` Harvest rain in the region in ml, rain during the months August and September.

`TimeYears:` Time since vintage, in years.

## Problem 1: Exploratory data analysis

```{r, echo = T}
wine_train <- read.csv("wine_train.csv")
str(wine_train)
```




```{r, echo = F}
wine_train %>% head %>% knitr::kable(digits = 2)
wine_train %>% summary
## Note LogPrice is logarithm of price and hence can be negative.
```

In the below scatterplot, we plot LogPrice against Temperature over all the years.
```{r, echo = F}
wine_train %>% 
  ggplot(aes(x = Temperature, y = LogPrice)) +  
  geom_point() + 
  ggtitle("LogPrice vs Temperature")
```

**1.** Choose the correct answers:  In this data set,

(A) there is exactly one data point with `Temperature` < 15.

(B) there are at least one data point with `Temperature` < 15.

(C) the maximum `Price` is 1.

(D) None of the above


```{r, echo = F}
wine_train_1 <- wine_train[1:14,2]
wine_train_2 <- wine_train[15:27,2]
boxplot(cbind(wine_train_1, wine_train_2), names = c("Period 1", "Period 2"), ylab = "LogPrice", main = "LogPrice over Year Produced")
```

\vspace{.1in}
**2.** The data from Years 1952-1980 is divided into two periods 1952 - 1967 and 1968-1980 to understand the impact of Year on LogPrice. From the side-by-side boxplot, which of the following is false?

(A) There is more variation in LogPrice in period 1 than period 2.

(B) On average, the price of wine is larger in period 1 than period 2.

(C) On average, the price of wine is smaller in period 1 than period 2.

(D) There is not enough information in the boxplot to conclude the relation between price and Year.

```{r, echo = F}
wine_train %>% 
  ggplot(aes(x = Year, y = LogPrice)) +  
  geom_point() + 
  ggtitle("LogPrice vs Year")
```
\vspace{.1in}
**3.** Which of the following is likely true?

(A) LogPrice increases with year on average and the trend is linear throughout.

(B) LogPrice decreases with year on average and the trend is linear for initial years but constant for later years.

(C) LogPrice decreases with year on average and the trend is linear throughout.

(D) LogPrice increases with year but not enough information related to trend. 


## Problem 2: Simple Linear Regression

For a more structured prediction, we use scatterplots of LogPrice versus  the variable Temperature. The following code shows the summary from the fit.
<!-- ```{r, echo = F} -->
<!-- par(mfrow = c(2,3)) -->
<!-- plot(wine_train$TimeYears, wine_train$LogPrice, xlab = "TimeYears", ylab = "LogPrice", -->
<!--           main = paste0("correlation = ", signif(cor(wine_train$TimeYears, wine_train$LogPrice))) -->
<!--      ) -->
<!-- plot(wine_train$WinterRain, wine_train$LogPrice, xlab = "WinterRain", ylab = "LogPrice", -->
<!--           main = paste0("correlation = ", signif(cor(wine_train$WinterRain, wine_train$LogPrice))) -->
<!--      ) -->
<!-- plot(wine_train$HarvestRain, wine_train$LogPrice, xlab = "HarvestRain", ylab = "LogPrice", -->
<!--           main = paste0("correlation = ", signif(cor(wine_train$HarvestRain, wine_train$LogPrice))) -->
<!--      ) -->
<!-- plot(wine_train$Temperature, wine_train$LogPrice, xlab = "Temperature", ylab = "LogPrice", -->
<!--           main = paste0("correlation = ", signif(cor(wine_train$Temperature, wine_train$LogPrice))) -->
<!--      ) -->
<!-- ``` -->
<!-- These plots along with the correlations (given above the plots), we decide to work first regress LogPrice on the variable Temperature. The following code shows the summary from the fit.  -->

```{r, echo = F}
fit1 <- lm(LogPrice ~ Temperature, data = wine_train)
summary(fit1)
```
\vspace{.1in}
**4.**  Which of the following is true? 

(A) The slope in this model is different from 0 at .01 level since $R^2=.446$ is large.

(B) The slope in this model is different from 0 at .01 level since the relevant p-value is .00014.

(C) The average LogPrice increases with Temperature since the slope estimate $0.643$ in the fit is positive.

(D) The slope in this model is zero at .01 level.

\vspace{.1in}
**5.** The $95\%$ confidence interval for the slope is given by


(A) $0 \pm 2\times 2.364$

(B) $0.643 \pm 2\times 2.364$

(C) $0.643 \pm 2\times 0.143$

(D) $0 \pm 2\times 0.143$


To diagnose the model, we use the residual and quantile plots.
```{r, echo = F}
par(mfrow = c(1,2))
plot(fit1, 1)
plot(fit1, 2)
```
\vspace{.1in}
**6.** Based on the diagnostic plots, which of the following is true?

(A) The linear model fit has no issues; all model assumptions seem to be satisfied.

(B) The errors do not have constant variance since the residual plot shows a fanned-out pattern.

(C) The errors do not have constant variance since the QQ plot shows deviation from the dotted line.

(D) The error distribution is close to normal.

\vspace{.1in}
**7.** Based on the prediction equation above, which will be the best approximation of a 95 prediction interval of Log Price for a wine with the following inputs: `Year = 1971`, `WinteRain` = 551, `Temperature`= 16.8, `HarvestRain`=112 and `TImeYears`=12.  

A) `r summary(fit1)$coef[1]` + `r summary(fit1)$coef[2]` $\times$ 551 $\pm$ 2 $\times$  `r summary(fit1)$sig`

B) `r summary(fit1)$coef[1]` + `r summary(fit1)$coef[2]` $\times$ 16.8 $\pm$ 2 $\times$ `r summary(fit1)$sig`

C) `r summary(fit1)$coef[1]` + `r summary(fit1)$coef[2]` $\times$ 551 $\pm$ 2 $\times$  `r summary(fit1)$coef[2,2]`

D) `r summary(fit1)$coef[1]` + `r summary(fit1)$coef[2]` $\times$ 16.8 $\pm$ 2 $\times$  `r summary(fit1)$coef[2, 2]`

E) more information is needed

<!-- `#r newcar_predict$fit` $\pm$ 2 $\times$ `r summary(fit1)$coef[2,2]` -->
## Multiple Linear Regression

To further improve on the model, we use multiple linear regression by including all the remaining variables into the simple linear regression model.
```{r, echo = F}
fit2 <- wine_train %>%
          as.data.frame %>%
          lm(LogPrice ~ TimeYears + WinterRain + Temperature + HarvestRain, data = .)
summary(fit2)
```
\vspace{.1in}
**8.** Based on the summary which variable can be removed from the multiple regression model so that all the coeffecients will not be zero at $\alpha = 0.03$ level? 

(A) TimeYears

(B) WinterRain

(C) Temperature

(D) HarvestRain

(E) None of the above
